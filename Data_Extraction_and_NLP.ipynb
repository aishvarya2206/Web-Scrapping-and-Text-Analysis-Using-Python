{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2RjsKiPh00Cs7HQo696K+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXPv2j56L5Yt","executionInfo":{"status":"ok","timestamp":1704273108348,"user_tz":-330,"elapsed":29490,"user":{"displayName":"Aishvarya Srivastava","userId":"00272959515118643299"}},"outputId":"965769c1-f50a-44dc-980c-243b4de156ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["##Data Extraction"],"metadata":{"id":"-HCe-TM4DAUR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6oA2TEmNY-M"},"outputs":[],"source":["!pip install requests\n","!pip install html5lib\n","!pip install bs4\n","!pip install textstat\n","!pip install XlsxWriter"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import re\n","import os\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string\n","import spacy\n","import textstat\n","from textstat.textstat import textstatistics\n","import xlsxwriter\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4hCd0g-MPxZ","executionInfo":{"status":"ok","timestamp":1704273181022,"user_tz":-330,"elapsed":22546,"user":{"displayName":"Aishvarya Srivastava","userId":"00272959515118643299"}},"outputId":"c42e50f8-4292-4d26-d30c-93c9e47e2173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["file_path = '/content/drive/My Drive/Test_Assignment/Input.xlsx'\n","df = pd.read_excel(file_path)\n","print(df.sample(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoq5EIyQNC9R","executionInfo":{"status":"ok","timestamp":1704276126201,"user_tz":-330,"elapsed":480,"user":{"displayName":"Aishvarya Srivastava","userId":"00272959515118643299"}},"outputId":"50c1622b-0b57-4cad-b277-cc87d5076c74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["             URL_ID                                                URL\n","38  blackassign0039  https://insights.blackcoffer.com/how-to-protec...\n","74  blackassign0075  https://insights.blackcoffer.com/how-to-overco...\n","60  blackassign0061  https://insights.blackcoffer.com/management-ch...\n","45  blackassign0046  https://insights.blackcoffer.com/all-you-need-...\n","64  blackassign0065  https://insights.blackcoffer.com/will-we-ever-...\n"]}]},{"cell_type":"code","source":["save_directory = '/content/drive/My Drive/Test_Assignment/WebScraped_Data/'\n","global fetch_url_404\n","fetch_url_404 = []\n","for index, row in df.iterrows():\n","    url = row['URL']\n","    urlid = row['URL_ID']\n","\n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","\n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            txt = soup.get_text()\n","            # Remove extra spaces and normalize whitespace\n","            cleaned_text = re.sub(r'\\n\\s*\\n', '.\\n', txt).strip()\n","            # Saving every website data in a text file with URL_ID as its file name\n","            filename = f\"{urlid}.txt\"\n","            filepath = os.path.join(save_directory, filename)\n","            with open(filepath, 'w', encoding='utf-8') as file:\n","\n","                file.write(cleaned_text)\n","                print(f\"Web content for {urlid} saved successfully at {filepath}.\")\n","            #print(f\"Title of {url}: {soup.title.get_text()}\")\n","\n","        else:\n","            print(f\"Failed to fetch {url}. Status code: {response.status_code}\")\n","            fetch_url_404.append(urlid)\n","    except Exception as e:\n","        print(f\"An error occurred while processing {url}: {e}\")\n"],"metadata":{"id":"o0vOIt1fMWA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stop_words_files = ['/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_Auditor.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_Currencies.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_DatesandNumbers.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_Generic.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_GenericLong.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_Geographic.txt',\n","                    '/content/drive/MyDrive/Test_Assignment/StopWords/StopWords_Names.txt']"],"metadata":{"id":"6lnoK3H0boc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read Stop Words Files\n","\n","stop_words = set()\n","\n","for file_name in stop_words_files:\n","    with open(file_name, 'r', encoding='latin-1') as file:\n","        words = file.read().split()\n","        stop_words.update(words)"],"metadata":{"id":"7V1kXFLNb2YP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def RemovePunctuationandTokenize(text):\n","  text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n","  tokens = word_tokenize(text_without_punctuation)\n","  return tokens"],"metadata":{"id":"q5eggOjZfUSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to count complex words in text\n","def count_complex_words(text):\n","  words = text.split()\n","  complex_word_count = 0\n","\n","  for word in words:\n","      syllable_count = textstat.syllable_count(word)\n","      if syllable_count >= 3:\n","          complex_word_count += 1\n","\n","  return complex_word_count\n","\n"],"metadata":{"id":"hz0vNSIMnVT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to count personal pronouns\n","def count_personal_pronouns(text):\n","    # Define the pattern for personal pronouns excluding \"US\" as a country\n","    pattern = r'\\b(?:I|we|my|ours|us)\\b(?![a-z])'\n","\n","    # Find all matches of personal pronouns in the text\n","    matches = re.findall(pattern, text, flags=re.IGNORECASE)\n","\n","    # Return the count of personal pronouns\n","    return len(matches)\n"],"metadata":{"id":"ExS7WlMbo7VI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Syllable Count Per Word\n","# Function to count syllables in a word\n","def count_syllables(word):\n","    vowels = \"aeiouy\"\n","    count = 0\n","    endings = [\"es\", \"ed\"]  # Exceptions for syllable counting\n","\n","    word = word.lower().strip(\".:;?!\")\n","\n","    if len(word) > 0:  # Check if word is not empty\n","        if word[-2:] in endings:  # Handle exceptions for syllable counting\n","            pass\n","        else:\n","            if word[0] in vowels:\n","                count += 1\n","            for index in range(1, len(word)):\n","                if word[index] in vowels and word[index - 1] not in vowels:\n","                    count += 1\n","            if word.endswith(\"e\"):\n","                count -= 1  # Exclude silent 'e' at the end\n","\n","    return max(1, count)  # At least one syllable per word\n"],"metadata":{"id":"4R4MdEZiorci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to calculate average word length\n","def calculate_average_word_length(text):\n","    # Split the text into words\n","    words = text.split()\n","\n","    # Calculate total number of characters in all words\n","    total_characters = sum(len(word) for word in words)\n","\n","    # Calculate total number of words\n","    total_words = len(words)\n","\n","    # Calculate average word length\n","    average_length = total_characters / total_words if total_words > 0 else 0\n","\n","    return average_length\n"],"metadata":{"id":"oSCjR7x3pcuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Fetch and preprocess each text file in the directory\n","save_directory = '/content/drive/My Drive/Test_Assignment/WebScraped_Data/'\n","\n","global excel_data\n","excel_data = list()\n","for filename in os.listdir(save_directory):\n","    if filename.endswith(\".txt\"):\n","        file_path = os.path.join(save_directory, filename)\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                content = file.read()\n","\n","                # Remove Punctuation and tokenize data\n","                preprocessed_content = RemovePunctuationandTokenize(content)\n","\n","                # Remove Stop Words\n","                filtered_tokens = [token for token in preprocessed_content if token.lower() not in stop_words]\n","\n","                # Positive Score\n","                positive_list_file = ['/content/drive/MyDrive/Test_Assignment/MasterDictionary/positive-words.txt']\n","                pos_words = set()\n","                Positive_Score = 0\n","                for file_name in positive_list_file:\n","                    with open(file_name, 'r', encoding='latin-1') as file:\n","                        words = file.read().split()\n","                        pos_words.update(words)\n","\n","                for pos in pos_words:\n","\n","                  if pos in filtered_tokens:\n","                    Positive_Score = Positive_Score + 1\n","\n","                print(\"Positive Score : \" , Positive_Score)\n","\n","                # Negative Score\n","                negative_list_file = ['/content/drive/MyDrive/Test_Assignment/MasterDictionary/negative-words.txt']\n","\n","                neg_words = set()\n","                Negative_Score = 0\n","                for file_name in negative_list_file:\n","                    with open(file_name, 'r', encoding='latin-1') as file:\n","                        words = file.read().split()\n","                        neg_words.update(words)\n","\n","                for neg in neg_words:\n","\n","                  if neg in filtered_tokens:\n","                    Negative_Score = Negative_Score + 1\n","\n","                print(\"Negative Score : \", Negative_Score)\n","\n","                # Polarity Score\n","                # Polarity Score = (Positive Score â€“ Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n","\n","                Polarity_Score = (Positive_Score - Negative_Score)/ ((Positive_Score + Negative_Score) + 0.000001)\n","                print(\"Polarity Score : \", Polarity_Score)\n","\n","                # Subjectivity Score\n","                # Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n","                num_token = len(filtered_tokens)\n","                Subjectivity_Score = (Positive_Score + Negative_Score)/ ((num_token) + 0.000001)\n","                print(\"Subjectivity Score : \", Subjectivity_Score)\n","\n","                ########### Analysis of Readability ###########\n","                # Avg Sentence length\n","\n","                # number of words\n","                num_word = len(preprocessed_content)\n","\n","                # number of sentences\n","                sentences = content.split('.')\n","                num_sentences = len(sentences)\n","\n","                # Adjust for cases where empty strings might cause incorrect counting\n","                if content.endswith('.'):\n","                    num_sentences -= 1\n","                # Average Sentence Length = the number of words / the number of sentences\n","                Average_Sentence_Length = num_word / num_sentences\n","                print(\"Average Sentence Length : \", Average_Sentence_Length)\n","\n","\n","                # Count complex words\n","                complex_words_count = count_complex_words(content)\n","\n","                # Display the number of complex words\n","                print(\"Number of complex words:\", complex_words_count)\n","\n","                # Percentage of Complex words = the number of complex words / the number of words\n","                # number of complex words\n","\n","                Percentage_of_complex_words = complex_words_count / num_word\n","                print(\"Percentage of Complex words : \", Percentage_of_complex_words)\n","\n","                # Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n","                Fog_Index = 0.4 * (Average_Sentence_Length + Percentage_of_complex_words)\n","                print(\"Fog Index : \", Fog_Index)\n","\n","                # Average Number of Words Per Sentence = the total number of words / the total number of sentences\n","                Average_Number_of_Words_Per_Sentence = num_word / num_sentences\n","                print(\"Average Number of Words Per Sentence : \", Average_Number_of_Words_Per_Sentence)\n","\n","                # Split the cleaned text into words\n","                words = content.split()\n","\n","                # Calculate syllable count per word\n","                syllable_count_per_word = {word: count_syllables(word) for word in words if word.strip()}\n","\n","                # ------------------------------------------------------------------------------#\n","                # Display syllable count per word\n","                sum_of_syllable = 0\n","                for word, syllable_count in syllable_count_per_word.items():\n","                    sum_of_syllable = sum_of_syllable + syllable_count\n","                    #print(f\"Word: {word} | Syllable Count: {syllable_count}\")\n","                avg_syllable = sum_of_syllable / num_word\n","                # ------------------------------------------------------------------------------#\n","\n","                # Calculate count of personal pronouns in the sample text\n","                pronoun_count = count_personal_pronouns(content)\n","\n","                # Display the count of personal pronouns\n","                print(\"Count of personal pronouns:\", pronoun_count)\n","\n","                ###########  Average Word Length  ###########\n","\n","                # Calculate average word length in the sample text\n","                avg_word_length = calculate_average_word_length(content)\n","\n","                # Display the average word length\n","                print(\"Average Word Length:\", avg_word_length)\n","\n","                # Creating list of directory to save in excel file\n","\n","                data = {\n","                              # 'URL_ID' : 'filename',\n","                              # 'URL' : url,\n","                              'POSITIVE SCORE' : Positive_Score,\n","                              'NEGATIVE SCORE' : Negative_Score,\n","                              'POLARITY SCORE' : Polarity_Score,\n","                              'SUBJECTIVITY SCORE' : Subjectivity_Score,\n","                              'AVERAGE SENTENCE LENGTH' : Average_Sentence_Length,\n","                              'PERCENTAGE OF COMPLEX WORDS' : Percentage_of_complex_words,\n","                              'FOG INDEX' : Fog_Index,\n","                              'AVERAGE NUMBER OF WORDS PER SENTENCE' : Average_Number_of_Words_Per_Sentence,\n","                              'COMPLEX WORD COUNT' : complex_words_count,\n","                              'WORD COUNT' : num_word,\n","                              'SYLLABLE PER WORD' : avg_syllable,\n","                              'PERSONAL PRONOUNS' : pronoun_count,\n","                              'AVG WORD LENGTH' : avg_word_length\n","                          }\n","                excel_data.append(data)\n","                print(excel_data)\n","\n","\n","        except Exception as e:\n","            print(f\"An error occurred while processing {filename}: {e}\")\n"],"metadata":{"id":"oJav2y_fcA-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import openpyxl\n","\n","# Load the existing workbook using xlsxwriter\n","existing_file = '/content/drive/MyDrive/Test_Assignment/Output Data Structure.xlsx'\n","\n","workbook = openpyxl.load_workbook(existing_file)\n","worksheet = workbook.active  # Access the active worksheet"],"metadata":{"id":"wUrMt90qAuXW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(fetch_url_404)\n","print(len(excel_data))\n","print(len(worksheet['A'])-14)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wndMMtKwyiy6","executionInfo":{"status":"ok","timestamp":1704282637804,"user_tz":-330,"elapsed":22,"user":{"displayName":"Aishvarya Srivastava","userId":"00272959515118643299"}},"outputId":"635c963d-fa20-416b-b77b-f5bd5bd8892d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['blackassign0036', 'blackassign0049']\n","98\n","101\n"]}]},{"cell_type":"code","source":["# Get values from column A and check for each target ID\n","for index , cell in enumerate(worksheet['A'] , start = 1):\n","\n","  if cell.value in fetch_url_404:\n","\n","        worksheet.cell(index , 3 , 'NA')\n","        worksheet.cell(index , 4 , 'NA')\n","        worksheet.cell(index , 5 , 'NA')\n","        worksheet.cell(index , 6 , 'NA')\n","        worksheet.cell(index , 7 , 'NA')\n","        worksheet.cell(index , 8 , 'NA')\n","        worksheet.cell(index , 9 , 'NA')\n","        worksheet.cell(index , 10 , 'NA')\n","        worksheet.cell(index , 11 , 'NA')\n","        worksheet.cell(index , 12 , 'NA')\n","        worksheet.cell(index , 13 , 'NA')\n","        worksheet.cell(index , 14 , 'NA')\n","        worksheet.cell(index , 15 , 'NA')\n","  else:\n","        if index <= len(excel_data):\n","              entry = excel_data[index - 1]  # Get the corresponding entry\n","              worksheet.cell(index+1, 3, entry.get('POSITIVE SCORE'))\n","              worksheet.cell(index+1, 4, entry.get('NEGATIVE SCORE'))\n","              worksheet.cell(index+1 , 5 , entry.get('POLARITY SCORE'))\n","              worksheet.cell(index+1 , 6 , entry.get('SUBJECTIVITY SCORE'))\n","              worksheet.cell(index+1 , 7 , entry.get('AVERAGE SENTENCE LENGTH'))\n","              worksheet.cell(index+1 , 8 , entry.get('PERCENTAGE OF COMPLEX WORDS'))\n","              worksheet.cell(index+1 , 9 , entry.get('FOG INDEX'))\n","              worksheet.cell(index+1 , 10 , entry.get('AVERAGE NUMBER OF WORDS PER SENTENCE'))\n","              worksheet.cell(index+1 , 11 , entry.get('COMPLEX WORD COUNT'))\n","              worksheet.cell(index+1 , 12 , entry.get('WORD COUNT'))\n","              worksheet.cell(index+1 , 13 , entry.get('SYLLABLE PER WORD'))\n","              worksheet.cell(index+1 , 14 , entry.get('PERSONAL PRONOUNS'))\n","              worksheet.cell(index+1 , 15 , entry.get('AVG WORD LENGTH'))\n","        else:\n","            # If index is out of excel_data range, write 'NA'\n","            for col_index in range(3, 16):\n","                worksheet.cell(index, col_index, 'NA')\n","\n","workbook.save(existing_file)\n"],"metadata":{"id":"voUm_cw4ArNx"},"execution_count":null,"outputs":[]}]}